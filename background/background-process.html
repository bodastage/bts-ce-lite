<h1>Background process</h1>
<script type="text/javascript">
	
const {ipcRenderer} = window.require('electron');
const { app, process } = window.require('electron').remote;
const { spawn, spawnSync, execSync } = window.require('child_process') 
const path = window.require('path');
const isDev = window.require('electron-is-dev');
const replace = window.require('replace-in-file');
const fs = window.require('fs');
const readChunk = window.require('read-chunk');
const fileType = window.require('file-type');
const gunzip = window.require('gunzip-file')
const log = window.require('electron-log');
const tar = window.require('tar');
const unzip = window.require('unzipper');
const unrar = window.require("node-unrar-js");
const fstream = window.require("fstream");
//const sync = window.require('sync');
const csv=window.require('csvtojson');
const utils = window.require('./background-utils');
const fixPath = window.require('fix-path');
const vendorFormats = window.require('./vendor-formats');
const VENDOR_CM_PARSERS = vendorFormats.VENDOR_CM_PARSERS;


log.info(`[parse_cm_job] Starting hidden window to run as background process`)
log.info(`PATH: ${process.env.PATH}`)



/*
* Extract rar file into targetFolder
*
* @param string fileName Name of file to extract 
* @param string targetFolder Name of destination folder
*/
extractRar = (fileName, targetFolder) => {
	try{
		var extractor = unrar.createExtractorFromFile(fileName, targetFolder);
		extractor.extractAll();
	}catch(e){
		log.error(e);
	}
}

/**
* Send log to UI 
*
*@param level string info|error|debug
*@param message string
*/
function sendLogToUI(task, level, message){
	ipcRenderer.send('parse-cm-job',task, JSON.stringify({status:level, message: message}))
}

/*
* Extract gz file into targetFolder
*
* @param string fileName Name of file to extract 
* @param string targetFolder Name of destination folder
*/
extractGzip =  (fileName, targetFolder) => {
	
	const targetFile = path.join(targetFolder, path.basename(fileName).replace(".gz",""));
	gunzip( fileName, targetFile);
	
}

/*
* Extract tar file into targetFolder
*
* @param string fileName Name of file to extract 
* @param string targetFolder Name of destination folder
*/
extractTar = (fileName, targetFolder) => {
	tar.x(  // or tar.extract(
	  {
		file: fileName,
		cwd: targetFolder,
		sync : true
	  }
	);
}

/*
* Unzip file into targetFolder
*
* @param string fileName Name of file to unzip 
* @param string targetFolder Name of destination folder
*/
extractZip = (fileName, targetFolder) => {
	/*var readStream = fs.createReadStream(fileName);
	let newFile = path.join(targetFolder, path.basename(fileName).replace(".zip", ""));
	
	log.info(`newFile: ${newFile}`);
	var writeStream = fstream.Writer(newFile);
	 
	readStream
	  .pipe(unzip.Parse())
	  .pipe(writeStream);
	  */
	  
	  fs.createReadStream(fileName).pipe(unzip.Extract({ path: targetFolder }));
}

/*
* Retun the extension and mime type of a file
*
* @param string filename 
*/
getFileType = (filename) => {
	let buffer = readChunk.sync(filename, 0, fileType.minimumBytes);
	return fileType(buffer);
}

/**
* Uncompress files in given folder 
* @param string folderName
*/
uncompressFiles = async (folderName) => {
	sendLogToUI('parse_data','info', `Uncompressing files in ${folderName} ... `);
	log.info(`[parse_cm_job] Uncompressing files in ${folderName} ...`)
	let files = fs.readdirSync(folderName,  { withFileTypes: true }).filter(dirent => !dirent.isDirectory()).map(dirent => dirent.name);
	
	let promiseArray = []
	
	for (let i=0; i<files.length; i++) {
		let filename = files[i];
		let filePath = path.join(folderName,filename)
		let fType = getFileType(filePath);
		
		try{
			if(fType.ext === 'gz' && fType.mime === 'application/gzip') {
				promiseArray.push(
					new Promise((resolve, reject) => {
					
						gunzip( filePath, filePath.replace('.gz',''), function() {
							log.info(`[parse_cm_job] Uncompressed  ${filename} successfully.`)
							sendLogToUI('parse_data','info', `Uncompressed  ${filename}. `);

							resolve(`Uncompressed  ${filename}. `)
						});
						
					})
				);
			}else{
				log.info(`[parse_cm_job] Skip uncompressing of ${filePath}`);
				sendLogToUI('parse_data','info', `[parse_cm_job] Skip uncompressing of ${filePath}`);
			}
		}catch(e){
			log.info(`[parse_cm_job] file:${filename} fType:${fType} error:${e.toString()}`)
			sendLogToUI('parse_data','error', `[parse_cm_job] file:${filename} fType:${fType} error:${e.toString()}`);
		}
	}
	
	let r = await Promise.all(promiseArray)
	return r
}

/*
* Use gunzip on windows.
* This is a work around to handle large files which are a problem for nodejs
* 
* @param string inputFile 
*/
winGunzipFile = (inputFile) => {
	let libPath = app.getAppPath();

	if (!isDev) {
	  libPath = process.resourcesPath;
	} 

	const gzip = path.join(libPath,'libraries','gzip.exe');
		
	const child = spawnSync(gzip, ['-d', inputFile]);
	log.info(`${gzip} -d ${inputFile}`);

	if(child.error){
		throw child.error.toString();
	}
}


/*
* Uncompress with 7z
*
*@param string fileName
*@param string targetFolder
*/
unCompressFile = (fileName, targetFolder) => {
	let libPath = app.getAppPath();
	if (!isDev) {
	  libPath = process.resourcesPath;
	} 

	//Windows
	if(process.platform === "win32"){
		let sevenZip = path.join(libPath,'libraries','7z.exe');

		const child = spawnSync(sevenZip, ['e', fileName,"-o"+targetFolder, "-y"]);
		
		log.info(`${sevenZip} e ${fileName} -o${targetFolder}`);

		log.info(`${child.stderr.toString()}`);
		
		if(child.error){
			throw child.error.toString();
		}else{
			log.info(child.stdout.toString());	
		}
	
	}else{
	
		let mime = getFileType(fileName).mime;
		
		//zip
		if(mime === 'application/zip'){
			extractZip(fileName, targetFolder);
		}
	
		//tar or tgz/tar.gz
		if(mime === 'application/x-tar' || 'application/x-gtar'){
			extractTar(fileName, targetFolder);
		}
		
		//rar
		if(mime === 'application/x-rar-compressed'){
			extractRar(fileName, targetFolder);
		}
		
		//gz
		if(mime === 'application/gzip'){
			extractGzip(fileName, targetFolder);
		}

	}
}

/*
* Uncompress gz files in a folder 
*
*@param string folderName
*/
uncompressFolder = (folderName) => {

	/**
	*Create backup folder for originals
	*/
	log.info(`[parse_cm_job] Create folder for original version of modified files(originals)...`);
	
	const originalsBackup = path.join(folderName,'originals');
	if (!fs.existsSync(originalsBackup)) {
		fs.mkdirSync(originalsBackup)	
	}
	
	let files = fs.readdirSync(folderName,  { withFileTypes: true }).filter(dirent => !dirent.isDirectory()).map(dirent => dirent.name);
	for (let i=0; i<files.length; i++) {
		let filePath = path.join(folderName,files[i]);
		let fType = getFileType(filePath);
		
		if(typeof fType === 'undefined'){
			sendLogToUI('parse_data','info', `[parse_cm_job] Skip uncompressing of ${filePath}`);
			continue;
		}
		
		try{
			if( fType.mime === 'application/gzip' || 
			fType.mime === 'application/zip' || 
			fType.mime === 'application/x-rar-compressed' || 
			fType.mime === 'application/x-tar' ||
			fType.mime === 'application/x-bzip2' ||
			fType.mime === 'application/x-lzip' ||
			fType.mime === 'application/x-lzma' ||
			fType.mime === 'application/x-7z-compressed' ||
			fType.mime === 'application/x-gtar'
			) {
				log.info(`Uncompressing ${files[i]}...`);
				sendLogToUI('parse_data','info', `Uncompressing  ${files[i]}...`);
				
				unCompressFile(filePath,folderName);
				
				//Move
				let newPath = path.join(originalsBackup, files[i]);
				fs.renameSync(filePath, newPath)
				
			}else{
				sendLogToUI('parse_data','info', `[parse_cm_job] Skip uncompressing of ${filePath}`);
				log.info(`[parse_cm_job] Skip uncompressing of ${filePath}`);
			}
		}catch(e){
			log.error(`[parse_cm_job] file:${filePath} fType:${fType.toString()} error:${e.toString()}`);
			sendLogToUI('parse_cm_job','error',e);
		}
	}
}

/**
* Clean Huawei GExport files.
*
*	sed -i -r "
*	s/_(BSC6900GSM|BSC6900UMTS|BSC6900GU|BSC6910GSM|BSC6910UMTS|BSC6910GU)//ig;
*	s/_(BTS3900|PICOBTS3900|BTS3911B|PICOBTS3911B|MICROBTS3900|MICROBTS3911B)//ig;
*	s/BSC(6910|6900)(UMTS|GSM)Function/FUNCTION/ig;
*	s/BSC(6910|6900)Equipment/EQUIPMENT/ig;
*	s/<class name=\"(.*)\"/<class name=\"\U\1\"/ig;
*	s/<class name=\"(.*)_MSCSERVER/<class name=\"\1/ig;
*	s/<class name=\"(.*)_ENODEB\"/<class name=\"\1\"/ig;
*   s/<class name=\"ENODEB([^\"]+)/<class name=\"\U\1/ig;
*	s/<class name=\"(.*)3900/<class name=\"\1/ig;
*	" /mediation/data/cm/huawei/raw/gexport/*.xml
*
* @exportFolder String Folder with the GExport dump XML files to be cleaned
*/
cleanHuaweiGexportFiles = async (exportFolder) => {	
	const replaceOptions = {
	  files: path.join(exportFolder,'*'),
	  from: [
		/\"(CELLALGOSWITCH|GTPU|CNOPERATOR|USERPRIORITY)_BSC(6900|6910)(U|GU|UMTS)\"/ig,
		/_(BSC6900GSM|BSC6900UMTS|BSC6900GU|BSC6910GSM|BSC6910UMTS|BSC6910GU)/ig,
		/_(BTS3900|PICOBTS3900|BTS3911B|PICOBTS3911B|MICROBTS3900|MICROBTS3911B|BTS5900)/ig,
		/BSC(6910|6900)(UMTS|GSM)Function/ig,
		/BSC(6910|6900)Equipment/ig,
		/<class name=\"(.*)\"/ig,
		/<class name=\"(.*)_MSCSERVER/ig,
		/<class name=\"(.*)_ENODEB\"/ig,
		/<class name=\"ENODEB([^\"]+)\"/,
		/<class name=\"(.*)3900/
	  ],
	  to: [
		(matchStr) => "\"U" + matchStr.match(/<class name=\"(.*)\"/)[1].toUpperCase() + "\"",
		"",
		"",
		"FUNCTION",
		"EQUIPMENT",
		(matchStr) => "<class name=\"" + matchStr.match(/\"(CELLALGOSWITCH|GTPU|CNOPERATOR|USERPRIORITY)_BSC(6900|6910)(U|GU|UMTS)\"/)[1].toUpperCase() + "\"",
		(matchStr) => "<class name=\"" + matchStr.match(/<class name=\"(.*)_MSCSERVER/)[1],
		(matchStr) => "<class name=\"" + matchStr.match(/<class name=\"(.*)_ENODEB\"/)[1] + "\"",
		(matchStr) => "<class name=\"" + matchStr.match(/<class name=\"ENODEB([^\"]+)\"/)[1] + "\"",
		(matchStr) => "<class name=\"" + matchStr.match(/<class name=\"(.*)3900/)[1]
	  ],
	};
	
	return await replace.sync(replaceOptions)
    
}



/**
* Clean Huawei GExport files.
*
*	sed -i -r "
*	s/<MO className="(BSC6900GSM|BSC6900UMTS|BSC6900GU|BSC6910GSM|BSC6910UMTS|BSC6910GU)(.*)/<MO className="\1/ig;
*	" /mediation/data/cm/huawei/raw/motree/*.xml
*
* @exportFolder String Folder with the MO Tree dump XML files to be cleaned
*/
cleanHuaweiMOTreeFiles = async (exportFolder) => {	
	const replaceOptions = {
	  files: path.join(exportFolder,'*'),
	  from: [
		/<MO className="(BSC6900GSM|BSC6900UMTS|BSC6900GU|BSC6910GSM|BSC6910UMTS|BSC6910GU)/g
	  ],
	  to: [
		"<MO className=\""
	  ],
	};
	
	return await replace.sync(replaceOptions)
}



/*Use gnu sed.exe on windows
* 
*/
cleanHuaweiGExportWithSed = (inputFolder) => {
	let libPath = app.getAppPath();

	if (!isDev) {
	  libPath = process.resourcesPath;
	} 
	
	let files = fs.readdirSync(inputFolder,  { withFileTypes: true }).filter(dirent => !dirent.isDirectory()).map(dirent => dirent.name);
		
	const sedScript = path.join(libPath,'libraries', 'gexport_cleanup.sed');
	const sed = path.join(libPath,'libraries','sed.exe');
		
	for (let i=0; i<files.length; i++) {
		f = files[i];
		inputFile = path.join(inputFolder,f);
		
		log.info(`Cleaning ${f}...`);
		sendLogToUI('parse_data','info', `Cleaning  ${f}...`);
		
		const child = spawnSync(sed, ['-i', '-r', '-f', sedScript, inputFile]);
		log.info(`${sed} -i -r -f ${sedScript} ${inputFile}`);

		if(child.error){
			log.info(`[parse_cm_job] error:${child.error.toString()}`);
			//ipcRenderer.send('parse-cm-job', JSON.stringify({status:"error", message: child.stderr.toString()}));
			throw child.error.toString();
		}
	}

}


/*
* Clean Huawei MO Tree XML files.
* @param string inputFolder
*/
cleanHuaweiMOTreeWithSed = (inputFolder) => {
	let libPath = app.getAppPath();

	if (!isDev) {
	  libPath = process.resourcesPath;
	} 
	
	let files = fs.readdirSync(inputFolder,  { withFileTypes: true }).filter(dirent => !dirent.isDirectory()).map(dirent => dirent.name);
		
	const sedScript = path.join(libPath,'libraries', 'motree_cleanup.sed');
	const sed = path.join(libPath,'libraries','sed.exe');
		
	for (let i=0; i<files.length; i++) {
		f = files[i];
		inputFile = path.join(inputFolder,f);
		
		log.info(`Cleaning ${f}...`);
		sendLogToUI('parse_data','info', `Cleaning  ${f}...`);
		
		const child = spawnSync(sed, ['-i', '-r', '-f', sedScript, inputFile]);
		log.info(`${sed} -i -r -f ${sedScript} ${inputFile}`);

		if(child.error){
			log.info(`[parse_cm_job] error:${child.error.toString()}`);
			throw child.error.toString();
		}
	}

}


/*
* Take the latest file when there is more than one file from the same node .
*
8 @param pathToFolder The name of the folder containing the GExport XML CM dumps
*/
removeDublicateHuaweiGExportFiles = (pathToFolder) => {
	
	//Create temp folder
	const repeatedFilesFolder = path.join(pathToFolder,'repeated_files');
	
	log.info(`[parse_cm_job] Creating folder for duplicate files: ${repeatedFilesFolder} ... `)
	sendLogToUI('parse_data','info', `[parse_cm_job] Creating folder for duplicate files: ${repeatedFilesFolder} ... `);
	
	if (!fs.existsSync(repeatedFilesFolder)) {
		fs.mkdirSync(repeatedFilesFolder)	
	}

	log.info("[parse_cm_job] Starting removal of duplicate gexport files...")
	sendLogToUI('parse_data','info', `[parse_cm_job] Creating folder for duplicate files: ${repeatedFilesFolder} ... `);
	//Key - value pair of node and the most recent file
	let nodeAndRecentFile = {};
	
	//items = fs.readdirSync(pathToFolder);
	items = fs.readdirSync(pathToFolder,  { withFileTypes: true }).filter(dirent => !dirent.isDirectory()).map(dirent => dirent.name);
	
	for (let i=0; i<items.length; i++) {
		let gexportFilename = items[i];
		let matches = gexportFilename.match(/(.*)_(\d+)\.xml.*/)
		
		sendLogToUI('parse_data','info', `Checking whether ${gexportFilename} is a duplicate... `);
		log.info(`[parse_cm_job] Checking whether ${gexportFilename} is a duplicate... `)
		
		if(matches === null) continue;
		
		let node = matches[1];
		let timestamp = matches[2];
		
		if( typeof nodeAndRecentFile[node] === 'undefined'){
			
			nodeAndRecentFile[node] = gexportFilename;
		}else{
			//Get timestamp on file in nodeAndRecentFile
			const mostRecentTimestamp = nodeAndRecentFile[node].match(/(.*)_(\d+)\.xml.*/)[2];

			if(parseInt(timestamp) > parseInt(mostRecentTimestamp)){
				let oldPath = path.join(pathToFolder, nodeAndRecentFile[node])
				let newPath = path.join(repeatedFilesFolder, nodeAndRecentFile[node])
				fs.renameSync(oldPath, newPath)
				
				nodeAndRecentFile[node] = gexportFilename;
			}
			
		}
	}
	
	nodeAndRecentFile = {};
	
	sendLogToUI('parse_data','info', `Duplicate file removal completed.`);
	log.info(`[parse_cm_job] Duplicate file removal completed.`)
	
}


processCMDumps = async (vendor, format, inputFolder, outputFolder) => {
	
	let basepath = app.getAppPath();

	if (!isDev) {
	  basepath = process.resourcesPath
	} 
	
	const parser = VENDOR_CM_PARSERS[vendor][format]
	const parserPath = path.join(basepath,'libraries',parser)
	
	
	//Clean Huawei GExport files 
	if(vendor === 'HUAWEI' && format === 'GEXPORT_XML'){
		try{
			removeDublicateHuaweiGExportFiles(inputFolder)
						
			log.info(`[parse_cm_job] Uncompressing files GExport XML files...`)
			sendLogToUI('parse_data','info',"Uncompressing files GExport XML files...");
			
			uncompressFolder(inputFolder);
			
			log.info(`[parse_cm_job] Uncompressing files GExport XML files...`)
			sendLogToUI('parse_data','info',`Cleaning GExport XML files...`);
			
			if(process.platform === "win32"){
				//If windows test, with sed.exe 
				cleanHuaweiGExportWithSed(inputFolder);
			}else{
				await cleanHuaweiGexportFiles(inputFolder);
			}
			
			log.info(`[parse_cm_job] Cleanup of GExport XML files completed.`);
			sendLogToUI('parse_data','info',`Cleanup of GExport XML files completed.`);
			
		}catch(error){
			log.error('Error occurred:', error);
			if(typeof error === 'undefined'){
				sendLogToUI('parse_data','error', 'Error occured.');
				return;
			}
			sendLogToUI('parse_data','error',error.toString());
			return;
		}
		
	}
	
	//Clean Huawei MOTree files 
	else if(vendor === 'HUAWEI' && format === 'MOTREE_XML'){
		try{
						
			log.info(`Uncompressing files MOTree XML files...`);
			sendLogToUI('parse_data','info', "Uncompressing files MOTree XML files...");
			
			uncompressFolder(inputFolder);
			
			log.info(`Uncompressing files MOTree XML files...`)
			sendLogToUI('parse_data','info',"Cleaning MOTree XML files...");
			
			if(process.platform === "win32"){
				//If windows test, with sed.exe 
				cleanHuaweiMOTreeWithSed(inputFolder);
			}else{
				await cleanHuaweiMOTreeFiles(inputFolder);
			}
			
			log.info(`Cleanup of MOTree XML files completed.`);
			sendLogToUI('parse_data','info',"Cleanup of MOTree XML files completed.");
			
		}catch(error){
			log.error('Error occurred:', error);
			if(typeof error === 'undefined'){
				sendLogToUI('parse_data','error', 'Error occured.');
				return;
			}
			sendLogToUI('parse_data','error',error.toString());
			return;
		}
		
	}
	
	
	//Uncompress files for other vendor format combinations except huawei gexport 
	//The reason for this is we want to first remove the duplicates in the dumps, before wasting time 
	//uncompressing what does not need to be uncompressed 
	//else if(vendor !== 'HUAWEI' && (format !== 'GEXPORT_XML' || format !== 'MOTREE_XML')){
	else{
		sendLogToUI('parse_data','info',"Uncompressing files...");
		log.info("Uncompressing files...")
		uncompressFolder(inputFolder);
	}
	
	sendLogToUI('parse_data','info', "Parsing files...");
	log.info("Parsing files...")
	

	
	let commandArgs  = ['-jar', parserPath, '-i',inputFolder,'-o',outputFolder];
	
	if( vendor.toLowerCase() === 'ericsson' && format === 'BSM') commandArgs[5] = path.join(outputFolder, "inv_bsm.csv")
	
	//Set the java heap to 1G if processing ZTE Plan template excel workbook
	if( vendor.toLowerCase() === 'zte' && format === 'XLS') commandArgs.unshift('-Xms1G');
	
	const child = spawn('java', commandArgs);
	log.info(`java ${commandArgs.join(" ")}`);
	
	child.stdout.on('data', (data) => {
	  log.info(data.toString());
	});

	child.stderr.on('data', (data) => {
	  sendLogToUI('parse_data','error', data.toString());
	  log.info(`[parse_cm_job] ${data.toString()}`)
	});
	
	child.on('exit', code => {
		if(code === 0 ){
			sendLogToUI('parse_data','success', `Dump successfully parsed. Find csv files in ${outputFolder}`);
			log.info(`[parse_cm_job] Dump successfully parsed. Find csv files in ${outputFolder}`);
		}else{
			log.error(`Something went wrong`);
			sendLogToUI('parse_data','error', `Something went wrong`);
		}
	});

}


/*
* Load CM Data into mongodb
* 
* @param string vendor 
* @param string format
* @param string csvFolder
*/
async function loadCMData(vendor, format, csvFolder){
	log.info(`vendor:${vendor} format:${format}, ${csvFolder}`);
	items = fs.readdirSync(csvFolder,  { withFileTypes: true }).filter(dirent => !dirent.isDirectory()).map(dirent => dirent.name);
	
	log.info(`Loading ${vendor} ${format} files from ${csvFolder}`);
	sendLogToUI('parse_data', 'info', `Loading ${vendor} ${format} files from ${csvFolder}` );
	
	for (let i=0; i<items.length; i++) {
		let fileName = items[i];
		let filePath = path.join(csvFolder, items[i]);
		let moName = items[i].replace(/.csv$/i,'');
		let table = `${vendor.toLowerCase()}_cm."${moName}"`;
		let table2 = `${vendor}_cm.\\"${moName}\\"`;
		
		sendLogToUI('load_cm_data','info', `Loading ${fileName} into ${table}`);
		
		//@TODO: pick database settings from sqlite db
		const child = spawn('psql', ['-U', 'bodastage', '-h', 'localhost', '-p', '5432', '-d', 'boda', '-c', `"COPY ${table2} (data) FROM STDIN;"` ],{
			env: {'PGPASSWORD':'password'},
			shell: true
		});
		
		child.stderr.on('data', (data) => {
		  log.error(data)
		});
		
		child.stdin.on('data', (data) => {
		  //console.log(`child.stdin.on.data: ${data}`);
		});
		
		
		await new Promise((resolve, reject) => {
			csv()
			.fromFile(filePath)
			.subscribe((json)=>{
				const jsonString = JSON.stringify(json);
				//console.log(`json:`, json);
				//log.log(`json:`, json);
				//log.log(`jsonString:`, jsonString);
				
				child.stdin.write(jsonString + '\n');

				log.info(`echo ${jsonString} | psql -U bodastage -h localhost -p 5432 -d boda -c "COPY ${table2} (data) FROM STDIN;"`);				
				
				if(child.error){
					throw child.error.toString();
				}else{
					log.info(child.stdout.toString());	
				}
			},(err) => {//onError
				console.error(err);
				child.stdin.end();
				reject();
			},
			()=>{//onComplete
				child.stdin.end();
				resolve(undefined);
				//console.log(`csv.fromStream.subscribe.end`);
				//end cild spawn
			}); 
			
		});

		
		
		
	}
	sendLogToUI('load_cm_data','success', `Completed loading data.`);
	
}
	


async function generateCSVReport(reportId, outputFolder){
	let reportInfo = await utils.getSQLiteReportInfo(reportId);
	let csvFileName = reportInfo.name.replace(/\s+/g,"_") + ".csv";
	//console.log(csvFileName, outputFolder, reportInfo.query);
	const reportFile = await utils.generateCSVFromQuery(csvFileName, outputFolder, reportInfo.query);
	sendLogToUI('download_report','success', reportFile);
}
	
	
/**
* Run database setup script
*
* @param string hostname 
* @param string port 
* @param string username 
* @param string password
*/	
function setupBodaDatabase(hostname, port, username, password){

	return new Promise((resolve, reject) => {
		try{
			let basepath = app.getAppPath();

			if (!isDev) {
			  basepath = process.resourcesPath
			} 
			
			let psql = "psql";
			
			if(process.platform === 'darwin'){
				psql = utils.getPathToPsqlOnMacOSX();
			}
			
			const sqlFile  = path.join(basepath, 'db', 'scripts', 'create_pg_database.sql');
			const child = spawnSync(psql, ['-U', username, '-h', hostname, '-p', port, '-f', sqlFile ],{
				env: {'PGPASSWORD': password},
				shell: true
			});
			
			log.info(`${psql} -U ${username} -h ${hostname} -p ${port} -f ${sqlFile}`);
			
			if(child.status != 0){
				log.error(`[backgroup_job:setupBodaDatabase] error:${child.output.toString()}`);
				sendLogToUI('setup_database','error', child.output.toString());
				//throw Error(child.output.toString());
				//reject(undefined);
			}else{
				log.info(child.output.toString())
				//resolve();
				sendLogToUI('setup_database','success', 'Database setup completed.');
			}
		}catch(e){
			sendLogToUI('setup_database','error', e);
		}
	});

}


/*
* Run backgroup task
*
*@param string task
*@param object options
*/	
async function  executeTask(task, options){
	log.info("executeTask(task, options) task:",task," options:", options);
	
	try {
		if(task === 'parse_data'){
			//@TODO: Move CM parsing to backgroup-utils.js
			if(options.dataType === 'CM' && options.vendor !== 'BODASTAGE'){
				processCMDumps(options.vendor, options.format, options.inputFolder, options.outputFolder)
			}else{
				const rtn = await utils.parseData(
						options.dataType, 
						options.vendor, 
						options.format, 
						options.inputFolder, 
						options.outputFolder, 
						//beforeFileParse
						(fileName) => { log.info(`Parsing ${fileName} ...`); },
						//afterFileParse
						(fileName) => { log.info(`Parsing ${fileName} done.`); },
						//beforeParse
						(fileName) => { log.info(`Parsing ${fileName} done.`); },
						//afterParse
						(fileName) => { log.info(`Parsing ${fileName} done.`); }
					);
				sendLogToUI(task, rtn.status, rtn.message);
			}
		}
		
		//@TODO: Change cssvFolder to inputFolder because we may load different data formats besides csv
		if(task === 'load_data'){
			const result = await utils.loadData(
				options.dataType || "CM", 
				options.vendor, 
				options.format, 
				options.csvFolder,
				options.truncateTables,
				(tableName, fileName, csvFolder, ) => { //beforeFileLoad
					log.info(`Loading ${fileName} into ${tableName}...`);
				}, 
				(tableName, fileName, csvFolder) => {}, 
				function beforeLoad(){
					sendLogToUI('load_data','info', 'Loading csv files into database...');
				}, 
				function afterLoad(){
					//sendLogToUI('load_data','success', 'Loading completed successfully.');
			});
			
			sendLogToUI(task, result.status, result.message);
			
			
		}
	}catch(err){
		log.error(err.toString());
		sendLogToUI('load_cm_data','error', err.toString());
	}
	
	
	//Download report
	try{
		if(task === 'download_report'){
			const reportFile = await utils.generateExcelOrCSV(options.filename, options.outputFolder, options.query, options.format,{
				reportId: options.reportId
			});
			sendLogToUI('download_report','success', reportFile);
		}
	}catch(err){
		sendLogToUI('download_report','error', err);
	}
	
	//Setup database -- 
	try{
		if(task === 'setup_database'){
			//setupBodaDatabase(options.hostname, options.port, options.username, options.password);
			const result = await utils.runMigrations(options.hostname, options.port, options.username, options.password, options.refreshSetup);
			sendLogToUI('setup_database',result.status, result.message);
		}
	}catch(err){
		sendLogToUI('setup_database','error', err);
	}
	
	//Run baseline 
	try{
		if(task === 'run_baseline'){
			const result = await utils.runBaseline(options.clustering, options.scoring, 
					(message) => sendLogToUI('run_baseline', 'info', message) );
			sendLogToUI('run_baseline',result.status, result.message);
		}
	}catch(err){
		log.error(err)
		sendLogToUI('run_baseline','error', "Error while running baseline.  Check logs for details.");
	}	
	
	//Upload baseline file
	try{
		if(task === 'upload_baseline'){
			const result = await utils.uploadUserBaseline(options.baselineFile);
			sendLogToUI('upload_baseline',result.status, result.message);
		}
	}catch(err){
		log.error(err)
		sendLogToUI('upload_baseline','error', "Error while running baseline.  Check logs for details.");
	}	
	
	//Upload parameter reference
	try{
		if(task === 'upload_parameter_reference'){
			const result = await utils.uploadParameterReference(options.referenceFile, options.clearTableBefore);
			sendLogToUI('upload_parameter_reference',result.status, result.message);
		}
	}catch(err){
		log.error(err)
		sendLogToUI('upload_parameter_reference','error', "Error while uploading parameter reference.  Check logs for details.");
	}	
	
	//Auto generate parameter reference 
	try{
		if(task === 'auto_generate_param_ref'){
			const result = await utils.autoGenerateParameterRef(options.clearTableBefore);
			sendLogToUI('auto_generate_param_ref',result.status, result.message);
		}
	}catch(err){
		log.error(err)
		sendLogToUI('auto_generate_param_ref','error', "Error while auto generating parameter reference.  Check logs for details.");
	}	
	
	//Download baseline reference
	try{
		if(task === 'download_baseline_reference'){
			const result = await utils.downloadBaselineReference(options.fileName, options.outputFolder, options.format);
			sendLogToUI(task, result.status, result.message);
		}
	}catch(err){
		log.error(err)
		sendLogToUI(task,'error', "Error while auto generating parameter reference.  Check logs for details.");
	}	
	
	//Add parameter to baseline reference 
	try{
		if(task === 'add_param_to_baseline'){
			const result = await utils.addParamToBaselineRef(options.vendor, options.tech, options.mo, options.parameter, options.baseline);
			sendLogToUI(task, result.status, result.message);
		}
	}catch(err){
		log.error(err)
		sendLogToUI(task,'error', "Error while auto generating parameter reference.  Check logs for details.");
	}		
	
	//
	//delete parameter to baseline reference 
	try{
		if(task === 'delete_baseline_parameter'){
			const result = await utils.deleteBaselineParameter(options.vendor, options.technology, options.mo, options.parameter);
			sendLogToUI(task, result.status, result.message);
		}
	}catch(err){
		log.error(err)
		sendLogToUI(task,'error', "Error while deleting parameter from baseline computation.  Check logs for details.");
	}	

	//
	//Import GIS File 
	try{
		if(task === 'upload_gis_file'){
			const result = await utils.importGISFile(options.importFile, options.format, options.truncateTable);
			sendLogToUI(task, result.status, result.message);
		}
	}catch(err){
		log.error(err)
		sendLogToUI(task,'error', "Error occured while importing file.  Check logs for details.");
	}

	//	clear_baseline_reference
	try{
		if(task === 'clear_baseline_reference'){
			const result = await utils.clearBaselineReference();
			sendLogToUI(task, result.status, result.message);
		}
	}catch(err){
		log.error(err)
		sendLogToUI(task,'error', "Error occured while clearing the baseline reference.  Check logs for details.");
	}
	
	//
	try{
		if(task === 'combine_csv_to_excel'){
			const result = await utils.combinedCSVsIntoExcel(options.csvDirectory, options.excelFormat, options.combine, options.outputFolder);
			sendLogToUI(task, result.status, result.message);
		}
	}catch(err){
		log.error(err)
		sendLogToUI(task,'error', "Error occured while combining csv files.  Check logs for details.");
	}
	
	//Generate KML
	try{
		if(task === 'generate_kml'){
			const result = await utils.generateKML(options);
			sendLogToUI(task, result.status, result.message);
		}
	}catch(err){
		log.error(err)
		sendLogToUI(task,'error', "Error occured while generating KML file.  Check logs for details.");
	}
}


ipcRenderer.on('parse-cm-job', (event, task, args) => {
	log.info(`Backgroup process: task: ${task} args: ${args}`);
	const obj  = JSON.parse(args)
	executeTask(task, obj);
})




ipcRenderer.send('ready')

</script>